{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all of these variables according to application\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = r\"E:\\Perk\\Data\\SavedModels\\UltrasoundBoneSegmentation-TF2_model-0_2020-07-28_11-19-31.h5\"\n",
    "# Path to testing images\n",
    "image_folder_path = r\"E:\\Perk\\Dataset\\Sub-evaluation-7-UNAM\\Sub-evaluation-7-UNAM\\train\\images\"\n",
    "# Folder to save output predictions in\n",
    "output_folder = r\"E:\\Perk\\Data\\Output\\UNAM\"\n",
    "# Optimal threshold for predictions, as determined by the training notebook\n",
    "best_thresh = 0.3\n",
    "# Notebook can only predict on 2d png, or 3d nrrd\n",
    "three_dim_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluation_metrics\n",
    "\n",
    "import nrrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(model_path,custom_objects={'loss': unet.weighted_categorical_crossentropy([0.1,0.9])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(input_arr,dsize,binarize):\n",
    "    arr = cv2.resize(input_arr, dsize=dsize, interpolation=cv2.INTER_AREA)\n",
    "    arr=arr/255\n",
    "    if binarize == True:\n",
    "        arr=arr>0\n",
    "        \n",
    "    arr = arr[:,:,np.newaxis]\n",
    "    arr = arr[np.newaxis,:,:,:]\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_array,final_pred_array = [],[]\n",
    "\n",
    "if three_dim_input == False:\n",
    "    image_dimensions,image_array = [],[]\n",
    "    for root, dirs, files in os.walk(image_folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_path=os.path.join(root, file)\n",
    "                filename_array.append(file)\n",
    "                arr=Image.open(image_path)\n",
    "                image_dimensions.append(arr.size)\n",
    "\n",
    "                image_array.preprocess_data(np.array(arr),(128,128),False)\n",
    "                \n",
    "                n_images = np.shape(image_array)[0]\n",
    "                \n",
    "                for image in range(n_images):\n",
    "                    pred = (model.predict(image_array[image]))[0][:,:,1]\n",
    "\n",
    "                    pred = cv2.resize(pred, dsize=image_dimensions[image])\n",
    "                    thresh_pred = pred>best_thresh\n",
    "\n",
    "                    save_path = os.path.join(output_folder,\"Prediction_\"+filename_array[image])\n",
    "                    plt.imsave(save_path, thresh_pred, cmap='binary_r')\n",
    "                    final_pred_array.append(thresh_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prediction for UNAM-Volume_074017.nrrd\n",
      "Saved prediction for UNAM-Volume_084043.nrrd\n",
      "Saved prediction for UNAM-Volume_084802.nrrd\n",
      "Saved prediction for UNAM-Volume_101150.nrrd\n",
      "Saved prediction for UNAM-Volume_102847.nrrd\n",
      "Saved prediction for UNAM-Volume_103837.nrrd\n",
      "Saved prediction for UNAM-Volume_105703.nrrd\n",
      "Saved prediction for UNAM-Volume_112618.nrrd\n"
     ]
    }
   ],
   "source": [
    "if three_dim_input == True:\n",
    "    for root, dirs, files in os.walk(image_folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.nrrd'):\n",
    "                \n",
    "                final_pred_array = []\n",
    "                                \n",
    "                image_dimensions_along_x = []\n",
    "                x_axis_images = []\n",
    "                \n",
    "                image_path=os.path.join(root, file)\n",
    "                filename_array.append(file)\n",
    "\n",
    "                data, header = nrrd.read(image_path)\n",
    "                \n",
    "                xDim = data.shape[0]\n",
    "                image_dimensions_along_x = np.shape(data[0,:,:])\n",
    "\n",
    "                # The x axis was chosen as the testing axis arbitrarily\n",
    "                # This is because the testing data does not tend to be oriented the same way across scans\n",
    "                for image in range(xDim):\n",
    "                    x_axis_images.append(preprocess_data(np.array(data[image,:,:]),(128,128),False))\n",
    "                    \n",
    "                    pred = (model.predict(x_axis_images[image])[0][:,:,1])\n",
    "\n",
    "                    pred = cv2.resize(pred, dsize=(zDim,yDim))\n",
    "                    thresh_pred = pred>best_thresh\n",
    "                    final_pred_array.append(thresh_pred)\n",
    "                    \n",
    "                save_path = os.path.join(output_folder,\"Prediction_\"+file)\n",
    "                \n",
    "                nrrd.write(save_path,(np.array(final_pred_array)).astype(int),header)\n",
    "                \n",
    "                print(\"Saved prediction for {}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO generate diagram of test predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
