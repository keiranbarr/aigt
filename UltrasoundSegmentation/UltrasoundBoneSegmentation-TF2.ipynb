{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2020-07-16_11-35-07\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"UltrasoundBoneSegmentation-TF2\"\n",
    "\n",
    "# Update these folder names for your computer\n",
    "# Contains all output\n",
    "output_data_folder = r\"E:\\Perk\\Data\"\n",
    "# Contains the training data\n",
    "images_data_folder = r\"E:\\Perk\\Dataset\\Sub-evaluation-6-Erasmus-MC\\Sub-evaluation-6-Erasmus-MC\\train\\images\"\n",
    "labels_data_folder = r\"E:\\Perk\\Dataset\\Sub-evaluation-6-Erasmus-MC\\Sub-evaluation-6-Erasmus-MC\\train\\labels\"\n",
    "\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 8\n",
    "class_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "'''\n",
    "Provide NxM numpy array to schedule cross validation\n",
    "N rounds of validation will be performed, leaving out M patients in each for validation data\n",
    "All values should be valid patient IDs, or negative. Negative values are ignored.\n",
    "\n",
    "Example 1: a leave-one-out cross validation with 3 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0],[1],[2]])\n",
    "\n",
    "Example 2: a leave-two-out cross validation on 10 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0,1],[2,3],[4,5],[6,7],[8,9]])\n",
    "\n",
    "Example 3: leave-one-out cross validation with 3 patients, then training on all available data (no validation):\n",
    "validation_schedule_patient = np.array([[0],[1],[2],[-1]])\n",
    "'''\n",
    "\n",
    "# The two variables below replace the previous variable validation_schedule_patient\n",
    "# because the new data is not organized by patient\n",
    "\n",
    "# functions as the dimension M in validation_schedule_patient\n",
    "percent_val_split = 20\n",
    "# functions as the dimension N in validation_schedule_patient\n",
    "num_validation_rounds = 1\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(output_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "(81, 1, 128, 128, 1)\n",
      "(81, 1, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# loads data, resizes it, and adds it to arrays\n",
    "\n",
    "ultrasound_array,segmentation_array = [],[]\n",
    "for root, dirs, files in os.walk(images_data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_path=os.path.join(root, file)\n",
    "            arr = np.array(Image.open(image_path))\n",
    "            \n",
    "            shape = arr.shape\n",
    "            x_axis, y_axis = shape[0], shape[1]\n",
    "            arr=zoom(arr,(128/x_axis,128/y_axis))\n",
    "            arr = arr[:,:,np.newaxis]\n",
    "            arr = arr[np.newaxis,:,:,:]\n",
    "            \n",
    "            ultrasound_array.append(arr)\n",
    "\n",
    "for root, dirs, files in os.walk(labels_data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            label_path=os.path.join(root, file)\n",
    "            arr = np.array(Image.open(label_path))\n",
    "            \n",
    "            shape = arr.shape\n",
    "            x_axis, y_axis = shape[0], shape[1]\n",
    "            arr=zoom(arr,(128/x_axis,128/y_axis))\n",
    "            arr = arr[:,:,np.newaxis]\n",
    "            arr = arr[np.newaxis,:,:,:]\n",
    "            \n",
    "            segmentation_array.append(arr)\n",
    "\n",
    "# This dimension isn't passed into the network, \n",
    "# It is just a way to organize all the arrays into one large array\n",
    "n_images = np.shape(ultrasound_array)[0]\n",
    "\n",
    "print(n_images)\n",
    "print(np.shape(ultrasound_array))\n",
    "print(np.shape(segmentation_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning 1 round(s) of validation\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation rounds\n",
    "\n",
    "# This situation would represent there is not enough data\n",
    "# to perform the desired split and number of validation rounds\n",
    "if percent_val_split*num_validation_rounds>100:\n",
    "    raise Exception(\"Percent split or number of rounds are too high\")\n",
    "\n",
    "print(\"Planning {} round(s) of validation\".format(num_validation_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2020-07-16_11-35-07\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    5\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     3.998e-05\n",
      "Batch size:          128\n",
      "Regularization rate: 0.0001\n",
      "\n",
      "Saving validation predictions in: E:\\Perk\\Data\\PredictionsValidation\n",
      "Saving models in:                 E:\\Perk\\Data\\SavedModels\n",
      "(0, 128, 128, 1)\n",
      "(0, 128, 128, 1)\n",
      "(0, 128, 128, 1)\n",
      "(0, 128, 128, 1)\n",
      "(17, 128, 128, 1)\n",
      "(64, 128, 128, 1)\n",
      "(17, 128, 128, 1)\n",
      "(64, 128, 128, 1)\n",
      "\n",
      "*** Leave-one-out round # 0\n",
      "    Training on 64 images, validating on 17 images...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-38172cba61d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"    Training on {} images, validating on {} images...\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mval_segmentation_data_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_segmentation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m# Create and train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\SpineUS\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for val_round_index in range(num_validation_rounds):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         np.shape(ultrasound_array)[2],\n",
    "         np.shape(ultrasound_array)[3],\n",
    "         np.shape(ultrasound_array)[4]])\n",
    "    \n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         np.shape(segmentation_array)[2],\n",
    "         np.shape(segmentation_array)[3],\n",
    "         np.shape(segmentation_array)[4]])\n",
    "    \n",
    "    val_ultrasound_data = train_ultrasound_data\n",
    "    val_segmentation_data = val_ultrasound_data\n",
    "    \n",
    "    print(np.shape(val_ultrasound_data))\n",
    "    print(np.shape(train_ultrasound_data))\n",
    "    print(np.shape(val_segmentation_data))\n",
    "    print(np.shape(train_segmentation_data))\n",
    "    \n",
    "    for image_index in range(n_images):\n",
    "        \n",
    "        # if the image at [image_index] falls into the range\n",
    "        # designated by the variable percent_val_split\n",
    "        if (val_round_index)*n_images*(percent_val_split/100) <= image_index < (val_round_index+1)*n_images*(percent_val_split/100):\n",
    "            #print(\"added image {} to validation split\".format(image_index))\n",
    "            val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                    ultrasound_array[image_index]))\n",
    "            val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                      segmentation_array[image_index]))\n",
    "            \n",
    "        else:\n",
    "            #print(\"added image {} to training split\".format(image_index))\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                    ultrasound_array[image_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                      segmentation_array[image_index]))\n",
    "    \n",
    "    n_train = np.shape(train_ultrasound_data)[0]\n",
    "    n_val = np.shape(val_ultrasound_data)[0]\n",
    "    \n",
    "    print(np.shape(val_ultrasound_data))\n",
    "    print(np.shape(train_ultrasound_data))\n",
    "    print(np.shape(val_segmentation_data))\n",
    "    print(np.shape(train_segmentation_data))\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(val_round_index))\n",
    "    print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # model.summary()\n",
    "        \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    if n_val > 0:\n",
    "        training_log = model.fit_generator(\n",
    "            training_generator,\n",
    "            validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "            epochs=num_epochs,\n",
    "            verbose=0)\n",
    "    else:\n",
    "        training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "    \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    if n_val > 0:\n",
    "        axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    if n_val > 0:\n",
    "        axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(val_round_index) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    if n_val > 0:\n",
    "        y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "        # Saving predictions for further evaluation\n",
    "\n",
    "        val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "        val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "        np.save(val_prediction_fullname, y_pred_val)\n",
    "\n",
    "        # Validation results\n",
    "\n",
    "        vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "            roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "            y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "        val_aurocs[val_round_index]          = vali_area\n",
    "        val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    if i in val_best_metrics.keys():\n",
    "        results_df.loc[i] = [\n",
    "            val_aurocs[i],\n",
    "            val_best_thresholds[i],\n",
    "            val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "        ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last ROC curve for visual verification that we catch the optimal point\n",
    "\n",
    "n = len(roc_thresholds)\n",
    "\n",
    "roc_x = np.zeros(n)\n",
    "roc_y = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    roc_x[i] = vali_metrics_dicts[i][evaluation_metrics.FALSE_POSITIVE_RATE]\n",
    "    roc_y[i] = vali_metrics_dicts[i][evaluation_metrics.SENSITIVITY]\n",
    "    # print(\"Threshold = {0:4.2f}  False pos rate = {1:4.2f}  Sensitivity = {2:4.2f}\"\n",
    "    #       .format(roc_thresholds[i], roc_x[i], roc_y[i]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.plot(roc_x, roc_y, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "num_vali = val_ultrasound_data.shape[0]\n",
    "num_show = 3\n",
    "if num_vali < num_show:\n",
    "    num_show = 0\n",
    "num_col = 4\n",
    "    \n",
    "indices = [i for i in range(num_vali)]\n",
    "sample_indices = sample(indices, num_show)\n",
    "sample_indices = [105, 195, 391]\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Uncomment for comparing the same images\n",
    "# sample_indices = [105, 195, 391, 133, 142]\n",
    "\n",
    "fig = plt.figure(figsize=(18, num_show*5))\n",
    "for i in range(num_show):\n",
    "    a0 = fig.add_subplot(num_show, num_col, i*num_col+1)\n",
    "    img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[i], :, :, 0].astype(np.float32)))\n",
    "    a0.set_title(\"Ultrasound #{}\".format(sample_indices[i]))\n",
    "    a1 = fig.add_subplot(num_show, num_col, i*num_col+2)\n",
    "    img1 = a1.imshow(np.flipud(val_segmentation_data_onehot[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a1.set_title(\"Segmentation #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "    a2 = fig.add_subplot(num_show, num_col, i*num_col+3)\n",
    "    img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a2.set_title(\"Prediction #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img2, fraction=0.046, pad=0.04)\n",
    "    a3 = fig.add_subplot(num_show, num_col, i*num_col+4)\n",
    "    img3 = a3.imshow((np.flipud(y_pred_val[sample_indices[i], :, :, 1]) > threshold), vmin=0.0, vmax=1.0)\n",
    "    c = fig.colorbar(img3, fraction=0.046, pad=0.04)\n",
    "    a3.set_title(\"Thresholded #{}\".format(sample_indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
