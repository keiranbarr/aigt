{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_notebook_name = \"UltrasoundBoneSegmentation-Train-TF2\"\n",
    "\n",
    "# Update these folder names for your computer\n",
    "# Contains all output\n",
    "output_data_folder = r\"E:\\Perk\\Data\"\n",
    "# Contains the training data\n",
    "images_data_folder = r\"E:\\Perk\\Dataset\\Sub-evaluation-6-Erasmus-MC\\Sub-evaluation-6-Erasmus-MC\\train\\images\"\n",
    "\n",
    "labels_data_folder = r\"E:\\Perk\\Dataset\\Sub-evaluation-6-Erasmus-MC\\Sub-evaluation-6-Erasmus-MC\\train\\labels\"\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 8\n",
    "class_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "        \n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "# The two variables below replace the previous variable validation_schedule_patient\n",
    "# because the new data is not organized by patient\n",
    "\n",
    "# designates the percent of data left out for validation\n",
    "percent_val_split = 10\n",
    "# designates the number of validation rounds\n",
    "num_validation_rounds = 1\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "#roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "#num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from scipy.ndimage import zoom\n",
    "import cv2\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(output_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data, resizes it, and adds it to arrays\n",
    "\n",
    "ultrasound_array,segmentation_array = [],[]\n",
    "for root, dirs, files in os.walk(images_data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_path=os.path.join(root, file)\n",
    "            \n",
    "            arr = np.array(Image.open(image_path))\n",
    "            arr = cv2.resize(arr, dsize=(128, 128), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            arr=arr/255\n",
    "            arr = arr[:,:,np.newaxis]\n",
    "            arr = arr[np.newaxis,:,:,:]\n",
    "            \n",
    "            ultrasound_array.append(arr)\n",
    "\n",
    "for root, dirs, files in os.walk(labels_data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            # TODO condense and clean this up\n",
    "            label_path=os.path.join(root, file)\n",
    "            \n",
    "            arr = np.array(Image.open(label_path))\n",
    "            arr = cv2.resize(arr, dsize=(128, 128), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            arr=(arr/255)>0\n",
    "            \n",
    "            arr = arr[:,:,np.newaxis]\n",
    "            arr = arr[np.newaxis,:,:,:]\n",
    "            \n",
    "            segmentation_array.append(arr)\n",
    "\n",
    "# This dimension isn't passed into the network, \n",
    "# It is just a way to organize all the arrays into one large array\n",
    "n_images = np.shape(ultrasound_array)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare validation rounds\n",
    "\n",
    "# This situation would represent there is not enough data\n",
    "# to perform the desired split and number of validation rounds\n",
    "if percent_val_split*num_validation_rounds>100:\n",
    "    raise Exception(\"Percent split or number of rounds are too high\")\n",
    "\n",
    "print(\"Planning {} round(s) of validation\".format(num_validation_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for val_round_index in range(num_validation_rounds):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         np.shape(ultrasound_array)[2],\n",
    "         np.shape(ultrasound_array)[3],\n",
    "         np.shape(ultrasound_array)[4]])\n",
    "    \n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         np.shape(segmentation_array)[2],\n",
    "         np.shape(segmentation_array)[3],\n",
    "         np.shape(segmentation_array)[4]])\n",
    "    \n",
    "    val_ultrasound_data = train_ultrasound_data\n",
    "    val_segmentation_data = train_segmentation_data\n",
    "    \n",
    "    for image_index in range(n_images):\n",
    "        \n",
    "        # if the image at [image_index] falls into the range\n",
    "        # designated by the variable percent_val_split\n",
    "        if (val_round_index)*n_images*(percent_val_split/100) <= image_index < (val_round_index+1)*n_images*(percent_val_split/100):\n",
    "            #print(\"added image {} to validation split\".format(image_index))\n",
    "            val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                    ultrasound_array[image_index]))\n",
    "            val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                      segmentation_array[image_index]))\n",
    "            \n",
    "        else:\n",
    "            #print(\"added image {} to training split\".format(image_index))\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                    ultrasound_array[image_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                      segmentation_array[image_index]))\n",
    "    \n",
    "    n_train = np.shape(train_ultrasound_data)[0]\n",
    "    n_val = np.shape(val_ultrasound_data)[0]\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(val_round_index))\n",
    "    print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # model.summary()\n",
    "        \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],[[]]\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    if n_val > 0:\n",
    "        training_log = model.fit_generator(\n",
    "            training_generator,\n",
    "            validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "            epochs=num_epochs,\n",
    "            verbose=0)\n",
    "    else:\n",
    "        training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "    \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    if n_val > 0:\n",
    "        axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    if n_val > 0:\n",
    "        axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(val_round_index) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    if n_val > 0:\n",
    "        y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "        # Saving predictions for further evaluation\n",
    "\n",
    "        val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "        val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "        np.save(val_prediction_fullname, y_pred_val)\n",
    "\n",
    "        # Validation results\n",
    "\n",
    "        vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "            roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "            y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "        val_aurocs[val_round_index]          = vali_area\n",
    "        val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    if i in val_best_metrics.keys():\n",
    "        results_df.loc[i] = [\n",
    "            val_aurocs[i],\n",
    "            val_best_thresholds[i],\n",
    "            val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "        ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last ROC curve for visual verification that we catch the optimal point\n",
    "\n",
    "n = len(roc_thresholds)\n",
    "\n",
    "roc_x = np.zeros(n)\n",
    "roc_y = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    roc_x[i] = vali_metrics_dicts[i][evaluation_metrics.FALSE_POSITIVE_RATE]\n",
    "    roc_y[i] = vali_metrics_dicts[i][evaluation_metrics.SENSITIVITY]\n",
    "    # print(\"Threshold = {0:4.2f}  False pos rate = {1:4.2f}  Sensitivity = {2:4.2f}\"\n",
    "    #       .format(roc_thresholds[i], roc_x[i], roc_y[i]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.plot(roc_x, roc_y, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "num_vali = val_ultrasound_data.shape[0]\n",
    "num_show = 3\n",
    "if num_vali < num_show:\n",
    "    num_show = 0\n",
    "num_col = 4\n",
    "    \n",
    "indices = [i for i in range(num_vali)]\n",
    "sample_indices = sample(indices, num_show)\n",
    "sample_indices = [10, 50, 100]\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Uncomment for comparing the same images\n",
    "# sample_indices = [105, 195, 391, 133, 142]\n",
    "\n",
    "fig = plt.figure(figsize=(18, num_show*5))\n",
    "for i in range(num_show):\n",
    "    a0 = fig.add_subplot(num_show, num_col, i*num_col+1)\n",
    "    img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[i], :, :, 0].astype(np.float32)))\n",
    "    a0.set_title(\"Ultrasound #{}\".format(sample_indices[i]))\n",
    "    a1 = fig.add_subplot(num_show, num_col, i*num_col+2)\n",
    "    img1 = a1.imshow(np.flipud(val_segmentation_data_onehot[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a1.set_title(\"Segmentation #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "    a2 = fig.add_subplot(num_show, num_col, i*num_col+3)\n",
    "    img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a2.set_title(\"Prediction #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img2, fraction=0.046, pad=0.04)\n",
    "    a3 = fig.add_subplot(num_show, num_col, i*num_col+4)\n",
    "    img3 = a3.imshow((np.flipud(y_pred_val[sample_indices[i], :, :, 1]) > threshold), vmin=0.0, vmax=1.0)\n",
    "    c = fig.colorbar(img3, fraction=0.046, pad=0.04)\n",
    "    a3.set_title(\"Thresholded #{}\".format(sample_indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
